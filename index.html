<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC"
          crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
          crossorigin="anonymous">
    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css
          integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous>
    <!-- Custom CSS -->
    <link href="style.css" rel="stylesheet">
    <link rel="icon" href="assets/infinigen_icon.svg">

    <title>Karhan Kayan</title>
  </head>
  <body>

    <div class="container mt-3">
      <div class="row">
        <div class="col-sm-0 col-md-1"></div>
        <div class="col-sm-12 col-md-3 mb-3">
          <img src="assets/pp_new.jpg" class="rounded img-fluid">
          <h1 class="mt-3">Karhan Kayan</h1>
          <p class="mt-1">
            I am a fourth-year Ph.D. candidate in computer science at Princeton University, advised by <a href="https://www.cs.princeton.edu/~jiadeng/" >Jia Deng</a> as a member of the <a href="https://pvl.cs.princeton.edu/"> Princeton Vision & Learning Lab</a>.
            I mainly work on 3D vision and computer graphics. 
          </p>
          <p>
            
          </p>
          <a href="mailto:kayankarhankaan@gmail.com" class="btn btn-black w-100 text-start ps-0"><i class="fa-solid fa-envelope"></i> E-Mail</a>
          <a href="https://scholar.google.com/citations?user=huNTBrMAAAAJ&hl=en" target="_blank" class="btn btn-black w-100 text-start ps-0"><i class="ai ai-google-scholar"></i> Google Scholar</a>
          <a href="https://x.com/karhankkayan" target="_blank" class="btn btn-black w-100 text-start ps-0"><i class="fa-brands fa-twitter"></i> Twitter</a>
          <a href="https://www.linkedin.com/in/karhankayan" target="_blank" class="btn btn-black w-100 text-start ps-0"><i class="fa-brands fa-linkedin"></i> LinkedIn</a>
          <a href="" target="_blank" class="btn btn-black w-100 text-start ps-0"><i class="fa-solid fa-file-pdf"></i> CV</a>
        </div>
        <div class="col-sm-12 col-md-6">

          <ul class="nav nav-tabs nav-fill mb-4" id="myTab" role="tablist">
            <li class="nav-item" role="presentation">
              <button class="nav-link active" id="highlights-tab" data-bs-toggle="tab" data-bs-target="#highlights-tab-pane" type="button" role="tab" aria-controls="highlights-tab-pane" aria-selected="true">Research Highlights</button>
            </li>
            <li class="nav-item" role="presentation">
              <button class="nav-link" id="all-tab" data-bs-toggle="tab" data-bs-target="#all-tab-pane" type="button" role="tab" aria-controls="all-tab-pane" aria-selected="false">All Publications</button>
            </li>
          </ul>
          <div class="tab-content" id="myTabContent">
            <div class="tab-pane fade show active" id="highlights-tab-pane" role="tabpanel" aria-labelledby="highlights-tab" tabindex="0">

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Princeton365: A Diverse Dataset with Accurate Camera Pose<span class="badge bg-secondary mx-1">ICCV 2025</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span> Stamatis Alexandropoulos*, Rishabh Jain, Yiming Zuo, Erich Liang, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: A large-scale and diverse SLAM/NVS benchmark with accurate camera pose enabled by a novel ground-truth collection method.</p>
                  <a href="https://arxiv.org/abs/2506.09035" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://princeton365.cs.princeton.edu/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/Princeton365" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/princeton365.mp4" type="video/mp4">
                </video>
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Towards Foundation Models for 3D Vision: How Close Are We? <span class="badge bg-secondary mx-1">3DV 2025</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span>, Yiming Zuo*, Maggie Wang, Kevin Jeon, Jia Deng, Thomas L. Griffiths (*equal contribution) </p>
                  <p class="card-text mt-2">TL;DR: 2D VLMs cannot solve 3D tasks. Specialized models are not robust enough for 3D foundation models.</p>
                  <a href="https://arxiv.org/abs/2410.10799" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://github.com/princeton-vl/UniQA-3D" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <img src="assets/depth_vis.jpg" class="card-img-bottom w-100">
              </div>


              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation<span class="badge bg-secondary mx-1">CVPR 2024</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span>, Alexander Raistrick*, Lingjie Mei*, David Yan, Yiming Zuo, Beining Han, Hongyu Wen, Meenal Parakh, Stamatis Alexandropoulos, Lahav Lipson, Zeyu Ma, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: A Blender-based procedural generator of photorealistic indoor scenes</p>
                  <a href="https://arxiv.org/abs/2406.11824" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://infinigen.org/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/infinigen" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <img src="assets/infinigen_indoors.jpeg" class="card-img-bottom w-100">
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Infinite photorealistic worlds using procedural generation <span class="badge bg-secondary mx-1">CVPR 2023</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted">Alexander Raistrick*, Lahav Lipson*, Zeyu Ma*, Lingjie Mei, Mingzhe Wang, Yiming Zuo, <span class="text-white">Karhan Kayan</span>, Hongyu Wen, Beining Han, Yihan Wang, Alejandro Newell, Hei Law, Ankit Goyal, Kaiyu Yang, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: Infinigen, a Blender-based procedural generator of photorealistic nature scenes.</p>
                  <a href="https://arxiv.org/abs/2306.09310" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://infinigen.org/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/infinigen" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                  <a href="https://www.youtube.com/watch?v=6tgspeI-GHY" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-youtube"></i>&nbsp;&nbsp;video</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/infinigen_nature.mp4" type="video/mp4">
                </video>
              </div>




            </div>

            <div class="tab-pane fade" id="all-tab-pane" role="tabpanel" aria-labelledby="all-tab" tabindex="0">

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Procedural Generation of Articulated Simulation-Ready Assets</div>
                <div class="card-body">
                  <p class="card-subtitle text-muted">Abhishek Joshi, Beining Han, Jack Nugent, Max Gonzalez Saez-Diez, Yiming Zuo, Jonathan Liu, Hongyu Wen, Stamatis Alexandropoulos, <span class="text-white">Karhan Kayan</span>, Zeyu Ma, Alexander Raistrick, Lingjie Mei, Jia Deng</p>
                  <p class="card-text mt-2">TL;DR: A toolkit for generating realistic, procedurally generated articulated assets for robotics simulation.</p>
                  <a href="https://arxiv.org/abs/2505.10755" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://infinigen.org/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/infinigen" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/articulations.mp4" type="video/mp4">
                </video>
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras<span class="badge bg-secondary mx-1">NeurIPS 2025</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted">Erich Liang, Roma Bhattacharjee, Sreemanti Dey, Rafael Moschopoulos, Caitlin Wang, Michel Liao, Grace Tan, Andrew Wang, <span class="text-white">Karhan Kayan</span>, Stamatis Alexandropoulos, Jia Deng</p>
                  <p class="card-text mt-2">TL;DR: A real-world benchmark providing per-frame ground truth intrinsics annotations for videos with dynamic camera intrinsics.</p>
                  <a href="https://arxiv.org/abs/2510.23589" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://influx.cs.princeton.edu/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/influx.mp4" type="video/mp4">
                </video>
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Princeton365: A Diverse Dataset with Accurate Camera Pose<span class="badge bg-secondary mx-1">ICCV 2025</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span> Stamatis Alexandropoulos*, Rishabh Jain, Yiming Zuo, Erich Liang, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: A large-scale and diverse SLAM/NVS benchmark with accurate camera pose enabled by a novel ground-truth collection method.</p>
                  <a href="https://arxiv.org/abs/2506.09035" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://princeton365.cs.princeton.edu/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/Princeton365" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/princeton365.mp4" type="video/mp4">
                </video>
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Towards Foundation Models for 3D Vision: How Close Are We? <span class="badge bg-secondary mx-1">3DV 2025</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span>, Yiming Zuo*, Maggie Wang, Kevin Jeon, Jia Deng, Thomas L. Griffiths (*equal contribution) </p>
                  <p class="card-text mt-2">TL;DR: 2D VLMs cannot solve 3D tasks. Specialized models are not robust enough for 3D foundation models.</p>
                  <a href="https://arxiv.org/abs/2410.10799" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://github.com/princeton-vl/UniQA-3D" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <img src="assets/depth_vis.jpg" class="card-img-bottom w-100">
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Infinigen Indoors: Photorealistic Indoor Scenes using Procedural Generation<span class="badge bg-secondary mx-1">CVPR 2024</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan*</span>, Alexander Raistrick*, Lingjie Mei*, David Yan, Yiming Zuo, Beining Han, Hongyu Wen, Meenal Parakh, Stamatis Alexandropoulos, Lahav Lipson, Zeyu Ma, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: A Blender-based procedural generator of photorealistic indoor scenes</p>
                  <a href="https://arxiv.org/abs/2406.11824" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://infinigen.org/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/infinigen" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                </div>
                <img src="assets/infinigen_indoors.jpeg" class="card-img-bottom w-100">
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Infinite photorealistic worlds using procedural generation <span class="badge bg-secondary mx-1">CVPR 2023</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted">Alexander Raistrick*, Lahav Lipson*, Zeyu Ma*, Lingjie Mei, Mingzhe Wang, Yiming Zuo, <span class="text-white">Karhan Kayan</span>, Hongyu Wen, Beining Han, Yihan Wang, Alejandro Newell, Hei Law, Ankit Goyal, Kaiyu Yang, Jia Deng (*equal contribution)</p>
                  <p class="card-text mt-2">TL;DR: Infinigen, a Blender-based procedural generator of photorealistic nature scenes.</p>
                  <a href="https://arxiv.org/abs/2306.09310" class="btn btn-dark btn-sm" target="_blank"><i class="ai ai-arxiv"></i>&nbsp;&nbsp;arXiv</a>
                  <a href="https://infinigen.org/" target="_blank" class="btn btn-dark btn-sm"><i class="fa-solid fa-house"></i> project page</a>
                  <a href="https://github.com/princeton-vl/infinigen" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-github"></i>&nbsp;&nbsp;code</a>
                  <a href="https://www.youtube.com/watch?v=6tgspeI-GHY" target="_blank" class="btn btn-dark btn-sm"><i class="fa-brands fa-youtube"></i>&nbsp;&nbsp;video</a>
                </div>
                <video muted autoplay loop class="card-img-bottom w-100">
                  <source src="assets/infinigen_nature.mp4" type="video/mp4">
                </video>
              </div>

              <div class="card text-white bg-dark mb-4 border-3">
                <div class="card-header">Orthogonal Decomposition of Modular Forms<span class="badge bg-secondary mx-1">UChicago REU 2019</span></div>
                <div class="card-body">
                  <p class="card-subtitle text-muted"><span class="text-white">Karhan Kayan</span></p>
                  <p class="card-text mt-2">An expository REU paper showing that the space of modular forms can be orthogonally decomposed into the space of Eisenstein series and the space of cusp forms.</p>
                  <a href="https://math.uchicago.edu/~may/REU2019/REUPapers/Kayan.pdf" class="btn btn-dark btn-sm" target="_blank"><i class="fa-solid fa-file-pdf"></i>&nbsp;&nbsp;PDF</a>
                </div>
                <img src="assets/modular_form.png" class="card-img-bottom w-50 mx-auto d-block">
              </div>



            </div>

            <div class="w-100 text-end">
              <p><small>
                This website is based on <a href="https://github.com/ebrach/ebrach.github.io"> Erich Brachmann's template</a>, which is based on <a href="https://jonbarron.info/">Jon Barron's template</a>.
              </small></p>

            </div>
          </div>





        </div>
        <div class="col-sm-0 col-md-2"></div>
      </div>
    </div>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>

        <script>
            window.addEventListener('load', videoScroll);
            window.addEventListener('scroll', videoScroll);

            function videoScroll() {

                if ( document.querySelectorAll('video[autoplay]').length > 0) {

                    var windowHeight = window.innerHeight,
                    videoEl = document.querySelectorAll('video[autoplay]');

                    for (var i = 0; i < videoEl.length; i++) {

                        var thisVideoEl = videoEl[i],
                            videoHeight = thisVideoEl.clientHeight,
                            videoClientRect = thisVideoEl.getBoundingClientRect().top;

                        if ( (thisVideoEl.parentNode.classList.contains('carousel-item') && thisVideoEl.parentNode.classList.contains('active')) || (thisVideoEl.parentNode.nodeName === 'DIV' && !thisVideoEl.parentNode.classList.contains('carousel-item') )) {
                            if ( videoClientRect <= ( (windowHeight) - (videoHeight*.8) ) && videoClientRect >= ( 0 - ( videoHeight*.2 ) ) ) {
                                thisVideoEl.play();
                            } else {
                                thisVideoEl.pause();
                            }
                        }
                    }
                }
            }
        </script>
  </body>
</html>